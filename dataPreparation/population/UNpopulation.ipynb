{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN FUNCTION - input\n",
    "\n",
    "## INPUT FILE\n",
    "# codemaps = pd.read_csv('codemaps.csv')\n",
    "country_names = pd.read_csv('../../../data/dl1_countrycodeorg_country_name.csv')\n",
    "UNcode_names = pd.read_csv('WPP2019_F01_LOCATIONS_DB.csv')\n",
    "UNcode_names = UNcode_names[['Country Code', 'LocID']]\n",
    "\n",
    "df_input_pop = pd.read_csv('WPP2019_PopulationByAgeSex_Medium.csv')\n",
    "df_input_pop_total = pd.read_csv('WPP2019_TotalPopulationBySex.csv')\n",
    "\n",
    "start_year = 2010\n",
    "end_year = 2051\n",
    "## OUTPUT FILE\n",
    "save_file_name = \"population_un.csv\"\n",
    "save_file_name_total = \"population_total.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data\n",
    "\n",
    "# ages = {'0-4': 'd0', '5-9': 'd05', '10-14': 'd10', '15-19': 'd15', \n",
    "#         '20-24': 'd20', '25-29': 'd25', '30-34': 'd30', '35-39': 'd35', \n",
    "#         '40-44': 'd40', '45-49': 'd45', '50-54': 'd50', '55-59': 'd55', \n",
    "#         '60-64': 'd60', '65-69': 'd65', '70-74': 'd70', '75-79': 'd75', \n",
    "#         '80-84': 'd80', '85-89': 'd85', '90-94': 'd90', '95-99': 'd95', \n",
    "#         '100+': 'd95'}\n",
    "ages = {'0-4': 'd0', '5-9': 'd5', '10-14': 'd10', '15-19': 'd15', \n",
    "        '20-24': 'd20', '25-29': 'd25', '30-34': 'd30', '35-39': 'd35', \n",
    "        '40-44': 'd40', '45-49': 'd45', '50-54': 'd50', '55-59': 'd55', \n",
    "        '60-64': 'd60', '65-69': 'd65', '70-74': 'd65', '75-79': 'd65', \n",
    "        '80-84': 'd65', '85-89': 'd65', '90-94': 'd65', '95-99': 'd65', \n",
    "        '100+': 'd65'}\n",
    "\n",
    "# def changevalue(x):\n",
    "#     return x * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please calculate the numbers and verify!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1404753, 443, 151, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Please calculate the numbers and verify!')\n",
    "len(df_input_pop), len(df_input_pop['LocID'].unique()), len(df_input_pop['Time'].unique()), len(df_input_pop['AgeGrp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873004\n"
     ]
    }
   ],
   "source": [
    "df = df_input_pop[['LocID', 'Location', 'Variant', 'Time', 'AgeGrp', 'PopMale', 'PopFemale']]\n",
    "# df = df[df['Variant']=='Medium']\n",
    "df = df.rename(columns={\"Time\": \"year\", \"AgeGrp\": 'age'})\n",
    "df['age'] = df['age'].apply(lambda x: ages[x])\n",
    "\n",
    "df_male = df[['LocID', 'Location', 'Variant', 'year', 'age', 'PopMale']]\n",
    "df_male['sex'] = 'M'\n",
    "df_male = df_male.rename(columns={\"PopMale\": \"population\"})\n",
    "\n",
    "df_female = df[['LocID', 'Location', 'Variant', 'year', 'age', 'PopFemale']]\n",
    "df_female['sex'] = 'F'\n",
    "df_female = df_female.rename(columns={\"PopFemale\": \"population\"})\n",
    "\n",
    "df_combined = pd.concat([df_male, df_female])\n",
    "\n",
    "gb = df_combined.groupby(['LocID', 'sex', 'age', 'year']).sum()\n",
    "print(len(gb))\n",
    "gb = gb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.pivot_table(gb, columns=['year'], index=['LocID', 'sex', 'age'], values='population')\n",
    "dff = dff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = dff.merge(UNcode_names, on='LocID').drop(columns=['LocID'])\n",
    "pop = pop.dropna(subset=['Country Code'])\n",
    "pop.replace('\\s+', '', regex=True, inplace=True)\n",
    "pop = pop[pop['Country Code'] != '']\n",
    "pop = pop.set_index(['Country Code', 'sex', 'age'])\n",
    "pop = (pop * 1000).astype('int')\n",
    "pop.reset_index().to_csv(save_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction from WB: ['AND', 'ASM', 'BMU', 'CYM', 'DMA', 'FRO', 'GIB', 'GRL', 'IMN', 'KNA', 'LIE', 'MAF', 'MCO', 'MHL', 'MNP', 'NRU', 'PLW', 'SMR', 'SXM', 'TCA', 'TUV', 'VGB', 'XKX'] 23\n",
      "Plus from WB: ['ESH', 'GLP', 'GUF', 'MTQ', 'MYT', 'PSE', 'REU', 'TWN'] 8\n",
      "Subtraction from GBD : ['AND', 'ASM', 'BMU', 'COK', 'DMA', 'GRL', 'KNA', 'MCO', 'MHL', 'MNP', 'NIU', 'NRU', 'PLW', 'SMR', 'TKL', 'TUV'] 16\n",
      "Plus from GBD : ['ABW', 'CHI', 'CUW', 'ESH', 'GLP', 'GUF', 'HKG', 'MAC', 'MTQ', 'MYT', 'NCL', 'PYF', 'REU'] 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def check_countries(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    countries = df['Country Code'].unique()\n",
    "    country_names = pd.read_csv('../../../data/dl1_countrycodeorg_country_name.csv')\n",
    "    GBD_countries = country_names[country_names[\"country\"].notnull()]['Country Code']\n",
    "    WB_countries = country_names[country_names[\"WBCountry\"].notnull()]['Country Code']\n",
    "    plus_GBD = sorted(list(set(countries) - set(GBD_countries)))\n",
    "    sub_GBD = sorted(list(set(GBD_countries) - set(countries)))\n",
    "    plus_WB = sorted(list(set(countries) - set(WB_countries)))\n",
    "    sub_WB = sorted(list(set(WB_countries) - set(countries)))\n",
    "\n",
    "    print ('Subtraction from WB:', sub_WB, len(sub_WB))\n",
    "    print ('Plus from WB:', plus_WB, len(plus_WB))\n",
    "    print ('Subtraction from GBD :', sub_GBD, len(sub_GBD))\n",
    "    print ('Plus from GBD :', plus_GBD, len(plus_GBD))\n",
    "check_countries(save_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do not sum up all population by sex and age. All countries have total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please calculate the numbers and verify!\n",
      "72027 1 477 151\n"
     ]
    }
   ],
   "source": [
    "print('Please calculate the numbers and verify!')\n",
    "df_tmp = df_input_pop_total[df_input_pop_total['Variant']=='Medium']\n",
    "print(len(df_tmp), len(df_tmp['Variant'].unique()), len(df_tmp['LocID'].unique()), len(df_tmp['Time'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_total = df_tmp.merge(UNcode_names, on='LocID')\n",
    "pop_total = pop_total[['Country Code', 'Time', 'PopTotal']]\n",
    "pop_total = pop_total.dropna(subset=['Country Code'])\n",
    "pop_total.replace('\\s+', '', regex=True, inplace=True)\n",
    "pop_total = pop_total[pop_total['Country Code'] != '']\n",
    "pop_total = pd.pivot_table(pop_total, columns=['Time'], index=['Country Code'], values='PopTotal')\n",
    "pop_total = (pop_total * 1000).astype('int')\n",
    "pop_total.reset_index().to_csv(save_file_name_total, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction from WB: ['XKX'] 1\n",
      "Plus from WB: ['AIA', 'BES', 'BLM', 'COK', 'ESH', 'FLK', 'GLP', 'GUF', 'MSR', 'MTQ', 'MYT', 'NIU', 'PSE', 'REU', 'SHN', 'SPM', 'TKL', 'TWN', 'VAT', 'WLF'] 20\n",
      "Subtraction from GBD : [] 0\n",
      "Plus from GBD : ['ABW', 'AIA', 'BES', 'BLM', 'CHI', 'CUW', 'CYM', 'ESH', 'FLK', 'FRO', 'GIB', 'GLP', 'GUF', 'HKG', 'IMN', 'LIE', 'MAC', 'MAF', 'MSR', 'MTQ', 'MYT', 'NCL', 'PYF', 'REU', 'SHN', 'SPM', 'SXM', 'TCA', 'VAT', 'VGB', 'WLF'] 31\n"
     ]
    }
   ],
   "source": [
    "check_countries(save_file_name_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population in GBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n",
      "32400\n"
     ]
    }
   ],
   "source": [
    "## MAIN FUNCTION - input\n",
    "## INPUT FILE\n",
    "def find_csv_filenames(path_to_dir, suffix=\".CSV\" ):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    return [filename for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "def change_df_columnnames(df): # change columnnames if download data with id and names\n",
    "    new_col = [col.split(\"_\")[0] if col.split(\"_\")[-1] == \"name\" else col for col in df.columns]\n",
    "    df.columns = new_col\n",
    "    del_col = [col for col in df.columns if (col.split(\"_\")[-1] == \"id\") and col.split(\"_\")[0] in new_col]\n",
    "    df_new = df.drop(columns=del_col)\n",
    "    df_new.rename(columns={'year_id' : \"year\"}, inplace=True)\n",
    "    return df_new\n",
    "\n",
    "file_dir = './IHME_GBD_2019_POP_2010_2019_0/'\n",
    "csv_files = find_csv_filenames(file_dir)\n",
    "## time\n",
    "MAXSIZE = 1\n",
    "\n",
    "\n",
    "\n",
    "ages_to_use = ['Under 5', '5 to 9', '10 to 14', '15 to 19', '20 to 24',\n",
    "       '25 to 29', '30 to 34', '35 to 39', '40 to 44', '45 to 49',\n",
    "       '50 to 54', '55 to 59', '60 to 64', '65 to 69', '70 to 74',\n",
    "       '75 plus']\n",
    "ages = {'Under 5': 'd0', '5 to 9': 'd5', '10 to 14': 'd10', '15 to 19': 'd15', \n",
    "        '20 to 24': 'd20', '25 to 29': 'd25', '30 to 34': 'd30', '35 to 39': 'd35', \n",
    "        '40 to 44': 'd40', '45 to 49': 'd45', '50 to 54': 'd50', '55 to 59': 'd55', \n",
    "        '60 to 64': 'd60', '65 to 69': 'd65', '70 to 74': 'd65', '75 plus': 'd65'}\n",
    "\n",
    "pieces = []\n",
    "for file in csv_files:\n",
    "    pop_input = pd.read_csv(file_dir + file)\n",
    "    pop_input = change_df_columnnames(pop_input)\n",
    "    pop_input = pop_input[pop_input['age'].isin(ages_to_use)]\n",
    "    pop_input = pop_input[pop_input['year']>=2010]\n",
    "    pieces.append(pop_input)\n",
    "    print(len(pop_input))\n",
    "pop_input = pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324000\n",
      "216000\n",
      "Please calculate the numbers and verify!\n",
      "188160\n",
      "672 2 14 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caozhong/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "countries_pri = pd.read_csv('../../data/dl1_countrycodeorg_country_name.csv')\n",
    "print(len(pop_input))\n",
    "pop_gbd = pop_input\n",
    "pop_gbd['sex'].replace(to_replace='female', value='F', inplace=True)\n",
    "pop_gbd['sex'].replace(to_replace='male', value='M', inplace=True)\n",
    "pop_gbd = pop_gbd[pop_gbd['sex'] != 'both']\n",
    "pop_gbd['age'] = pop_gbd['age'].apply(lambda x: ages[x])\n",
    "print(len(pop_gbd)) ##\n",
    "print('Please calculate the numbers and verify!')\n",
    "gb = pop_gbd.groupby(['measure', 'location', 'sex', 'age', 'metric', 'year']).sum()\n",
    "print(len(gb))\n",
    "pop_gbd = gb.reset_index()\n",
    "print(len(pop_gbd['location'].unique()), len(df['sex'].unique()), len(df['age'].unique()),len(df['year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('../../data/dl1_countrycodeorg_country_name.csv')\n",
    "code_map = dict(zip(countries.country, countries['Country Code'])) \n",
    "pop_gbd = pop_gbd[pop_gbd['location'].isin(countries.country)]\n",
    "pop_gbd['Country Code'] = pop_gbd['location'].apply(lambda x:code_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gbd_saved = pd.pivot_table(pop_gbd, columns=['year'], index=['Country Code', 'sex', 'age'], values='val')\n",
    "pop_gbd_saved.reset_index().to_csv('population_gbd.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c313004aacb210e2a0b0ec8e97d422a11096aa68fd78b262a7f6f720f4307dc6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
